{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>***EDA and engineering of Quality***<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***1. EDA -- What makes a review a good review?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>used dataset: review_1918.csv<u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.1 Import necessary modules***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# -------------------------------- \n",
    "\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en.examples import sentences\n",
    "\n",
    "#!ln -s /Users/felixbecker/neuefische/Yelp-Capstone/modeling/Language.py Language.py\n",
    "#from Language import language_processing\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.2 Set global parameters***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 6, 4\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.3 Import dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = pd.read_csv('../data/yelp_dataset/review_1819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.query(\"useful != 0\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.4 Overview of the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev['stars'] = df_rev['stars'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.5 Cleaning the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping 'Unnamed: 0', 'date', 'year'\n",
    "\n",
    "df_rev.drop(['Unnamed: 0', 'date', 'year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.6 Gain information on rating***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = ['#43948c', '#36a097', '#28aea2', '#1bbbad', '#0dc9b8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df_rev, x='stars', palette=sns.color_palette(palette, 5), zorder=2)\n",
    "plt.title('Distribution of star ratings')\n",
    "plt.ylim(0, 1000000)\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('Count')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "# plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df_rev.query('useful != 0'), x='stars', palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 350000)\n",
    "plt.ylabel('# of reviews rated useful')\n",
    "plt.title('Number of reviews ranked \"useful\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df_rev, x='stars', y='useful', estimator=lambda x : round(sum(x==0)*100.0/len(x),2), palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('% of reviews rated useful')\n",
    "plt.title('Percentage of reviews ranked \"useful\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df_rev.query('funny != 0'), x='stars', palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 80000)\n",
    "plt.ylabel('# of reviews rated funny')\n",
    "plt.title('Number of reviews ranked \"funny\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df_rev, x='stars', y='funny', estimator=lambda x : round(sum(x==0)*100.0/len(x),2), palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('% of reviews rated funny')\n",
    "plt.title('Percentage of reviews ranked \"funny\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=df_rev.query('cool != 0'), x='stars', palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 250000)\n",
    "plt.ylabel('# of reviews rated cool')\n",
    "plt.title('Number of reviews ranked \"cool\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df_rev, x='stars', y='cool', estimator=lambda x : round(sum(x==0)*100.0/len(x),2), palette='viridis_r', zorder=2)\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('% of reviews rated cool')\n",
    "plt.title('Percentage of reviews ranked \"cool\" per star rating')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_rev.drop(['review_id', 'user_id', 'business_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr.corr(), annot=True, cmap='viridis_r', linewidth=0.01, linecolor='k', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1.7 Gain information on texts***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique words per review and save it to new column\n",
    "\n",
    "df_rev['unique_words'] = df_rev['text'].apply(lambda x : len(set(str(x).split())))\n",
    "\n",
    "# Get the number of used exclamation marks per review\n",
    "\n",
    "df_rev['count_excl'] = df_rev['text'].str.count('!')\n",
    "\n",
    "# Remove punctuation\n",
    "\n",
    "df_rev[\"no_punct\"] = df_rev['text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Get the length of each review and save it to new column\n",
    "\n",
    "df_rev['text_length'] = df_rev['no_punct'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean text length per star rating and save in list\n",
    "\n",
    "mean_lengths = []\n",
    "mean_text_one = df_rev.query('stars == 1').text_length.mean().astype(int)\n",
    "mean_lengths.append(mean_text_one)\n",
    "mean_text_two = df_rev.query('stars == 2').text_length.mean().astype(int)\n",
    "mean_lengths.append(mean_text_two)\n",
    "mean_text_three = df_rev.query('stars == 3').text_length.mean().astype(int)\n",
    "mean_lengths.append(mean_text_three)\n",
    "mean_text_four = df_rev.query('stars == 4').text_length.mean().astype(int)\n",
    "mean_lengths.append(mean_text_four)\n",
    "mean_text_five = df_rev.query('stars == 5').text_length.mean().astype(int)\n",
    "mean_lengths.append(mean_text_five)\n",
    "\n",
    "mean_stars = [1.0, 2.0, 3.0, 4.0, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=mean_stars, y=mean_lengths, palette='viridis_r', zorder=2)\n",
    "plt.title('Mean text length per star rating')\n",
    "plt.ylim(0, 800)\n",
    "plt.ylabel('mean text length')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_rev['text_length'], bins=100)\n",
    "plt.title('Distribution of text length')\n",
    "plt.xlim(0, 6000)\n",
    "plt.ylim(0, 0.00225)\n",
    "plt.xlabel('text length')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_rev['unique_words'], bins=100)\n",
    "plt.title('Distribution of unique words')\n",
    "plt.xlim(0, 600)\n",
    "plt.ylim(0, 0.014)\n",
    "plt.xlabel('# of unique words')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=df_rev, x='stars', y='count_excl', estimator=lambda x : round(sum(x==0)*100.0/len(x),2), palette='viridis_r', zorder=2)\n",
    "plt.title('Percentage of exclamation marks per star rating ')\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('% of exlamation marks')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.bar_label(ax.containers[0], padding=-15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_excl = df_rev.drop(['review_id', 'user_id', 'business_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr_excl.corr(), annot=True, cmap='viridis_r', linewidth=0.01, linecolor='k', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***2. Language and spelling***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***2.1 Language processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the language per review with a certainty of at least 95%\n",
    "# Drop all other languages than english\n",
    "# Return the corresponding dataframe\n",
    "\n",
    "language_processing(df_rev);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning in language_processing is not applied in place!\n",
    "\n",
    "df_rev = df_rev[df_rev['language'] == 'English']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***2.2 Create word clouds for useful, funny and cool***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_use = df_rev[df_rev['useful'] != 0]\n",
    "df_fun = df_rev[df_rev['funny'] != 0]\n",
    "df_cool = df_rev[df_rev['cool'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the stopword list:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# update the stopwords after generating the first few clouds with non decisive words\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "# create a wordcloud using all the text in text\n",
    "text_use = \" \".join(text for text in df_use['text'])\n",
    "text_fun = \" \".join(text for text in df_fun['text'])\n",
    "text_cool = \" \".join(text for text in df_cool['text'])\n",
    "\n",
    "#remove the stopwords from the text\n",
    "wordcloud_use = WordCloud(stopwords=stopwords).generate(text_use)\n",
    "wordcloud_fun = WordCloud(stopwords=stopwords).generate(text_use)\n",
    "wordcloud_cool = WordCloud(stopwords=stopwords).generate(text_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***World Cloud for reviews rated as useful***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_use, interpolation='bilinear')\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***World Cloud for reviews rated as funny***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_fun, interpolation='bilinear')\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***World Cloud for reviews rated as cool***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_cool, interpolation='bilinear')\n",
    "plt.axis(\"off\");\n",
    "#print(wordcloud_cool.words_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***2.3 Text cleaning and building N-grams for useful, funny and cool rated reviews***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text cleaning and Lemmatization\n",
    "\n",
    "def text_cleaning(txt):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "    stopwords.extend(additional_stopwords)\n",
    "    txt = (unicodedata.normalize('NFKD', txt)).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower()\n",
    "    words = re.sub(r'[^\\w\\s]', '', txt).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the basic text cleaning and Lemmatization on each word list\n",
    "\n",
    "words_use = text_cleaning(''.join(str(df_use['text'].tolist())))\n",
    "words_fun = text_cleaning(''.join(str(df_fun['text'].tolist())))\n",
    "words_cool = text_cleaning(''.join(str(df_cool['text'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Building\" the N-grams of size 3 (Trigrams)\n",
    "# CAREFUL THIS TAKES MORE THAN 4 HOURS\n",
    "\n",
    "trigrams_use = (pd.Series(nltk.ngrams(words_use, 3)).value_counts())[:10]\n",
    "trigrams_fun = (pd.Series(nltk.ngrams(words_fun, 3)).value_counts())[:10]\n",
    "trigrams_cool = (pd.Series(nltk.ngrams(words_cool, 3)).value_counts())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=trigrams_use.values, y=trigrams_use.index, palette='viridis_r', zorder=2)\n",
    "plt.title('Most common trigrams in \"useful\"')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.xlim(0,4500)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Trigrams')\n",
    "plt.bar_label(ax.containers[0], padding=-30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=trigrams_fun.values, y=trigrams_fun.index, palette='viridis_r', zorder=2)\n",
    "plt.title('Most common trigrams in \"funny\"')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.xlim(0,1200)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Trigrams')\n",
    "plt.bar_label(ax.containers[0], padding=-30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=trigrams_cool.values, y=trigrams_cool.index, palette='viridis_r', zorder=2)\n",
    "plt.title('Most common trigrams in \"cool\"')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.xlim(0,3000)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Trigrams')\n",
    "plt.bar_label(ax.containers[0], padding=-30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***2.4 Create word clouds for reviews with star ratings ≤ 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bad = df_rev[df_rev['stars'] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the stopword list:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# update the stopwords after generating the first few clouds with non decisive words\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "text_bad = \" \".join(text for text in df_bad['text'])\n",
    "wordcloud_bad = WordCloud(stopwords=stopwords).generate(text_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Word Cloud for \"bad\" reviews***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_bad, interpolation='bilinear')\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bad = text_cleaning(''.join(str(df_bad['text'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_bad = (pd.Series(nltk.ngrams(words_bad, 3)).value_counts())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=trigrams_bad.values, y=trigrams_bad.index, palette='viridis_r', zorder=2)\n",
    "plt.title('Most common trigrams in \"bad\" reviews (star rating ≤ 2)')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.xlim(0,3500)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Trigrams')\n",
    "plt.bar_label(ax.containers[0], padding=-30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***2.5 Create word clouds for reviews with star ratings ≥ 4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = df_rev[df_rev['stars'] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the stopword list:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# update the stopwords after generating the first few clouds with non decisive words\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "text_good = \" \".join(text for text in df_good['text'])\n",
    "wordcloud_good = WordCloud(stopwords=stopwords).generate(text_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud_good, interpolation='bilinear')\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_good = text_cleaning(''.join(str(df_good['text'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_good = (pd.Series(nltk.ngrams(words_good, 3)).value_counts())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=trigrams_good.values, y=trigrams_good.index, palette='viridis_r', zorder=2)\n",
    "plt.title('Most common trigrams in \"good\" reviews (star rating ≥ 4)')\n",
    "plt.grid(which='major', axis='both', color='#C9C9C9', linestyle=':', zorder=0)\n",
    "plt.xlim(0,10000)\n",
    "plt.xlabel('# of occurrences')\n",
    "plt.ylabel('Trigrams')\n",
    "plt.bar_label(ax.containers[0], padding=-30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***3. Rating and Rating***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***3.1 Useful 1-5 Stars***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ce5e151fb00091df5b1b9e0901c9540dd87c25621af86a4204e4865fde1e8b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
