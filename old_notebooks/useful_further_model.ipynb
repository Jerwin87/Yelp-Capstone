{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# importing all needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer, matthews_corrcoef\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import re\n",
    "import unicodedata\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set Randomseed\n",
    "RSEED = 42\n",
    "\n",
    "# import needed functions\n",
    "from scripts.processing import *\n",
    "# from scripts.mk_categories_word2vec_addmaincat import select_dataset_by_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('../data/yelp_dataset/review_1819.csv').iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = language_processing(dfr, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "def text_cleaning(txt):\n",
    "    # txt = (unicodedata.normalize('NFKD', txt)).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower()\n",
    "    txt = txt.lower()\n",
    "    words = re.sub(r'[^\\w\\s]', '', txt).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maincat = select_dataset_by_cat(categories=None, save_to_csv=False)\n",
    "# dfr_maincat = dfr.set_index('business_id').join(maincat.set_index('business_id'), on='business_id', how='left', rsuffix='_business')\n",
    "# dfr = dfr_maincat.query('maincat == \"restaurants\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize vectorizer Parameter nach Susan Li\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, \n",
    "                             min_df=5, \n",
    "                             norm='l2', \n",
    "                             encoding='utf-8', \n",
    "                             ngram_range=(1, 3), \n",
    "                             stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_clicked = dfr.query('useful > 0 or cool > 0 or funny > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into feature and target \n",
    "X_clicked = dfr_clicked['text'].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "# X = np.array(dfr['text'].apply(lambda x: len(x))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfr.eval('useful_cool = useful + cool', inplace=True)\n",
    "# y = dfr['useful_cool'].apply(lambda x: 1 if x > 1 else 0)\n",
    "# y_clicked = dfr_clicked['useful'].apply(lambda x: 1 if x > 1 else 0)\n",
    "y_clicked = dfr_clicked['useful'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "X_train_clicked, _, y_train_clicked, _ = train_test_split(X_clicked, y_clicked, random_state=RSEED, stratify=y_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_test = pd.read_csv('../data/yelp_dataset/review_1819.csv').iloc[100000:125000]\n",
    "X_test_clicked = dfr_test['text'].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "y_test_clicked = dfr_test['useful'].apply(lambda x: 1 if x > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(cm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    return (tp*tn-fp*fn) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the vectorizer\n",
    "X_train_clicked = vectorizer.fit_transform(X_train_clicked)\n",
    "X_test_clicked = vectorizer.transform(X_test_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_clicked.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_clicked.query('useful > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_linsvc = {'penalty':('l1','l2'),\n",
    "                'loss': ('hinge', 'squared_hinge'),\n",
    "                'C': [0.02, 0.025, 0.03, 0.035, 0.04, 0.05, 0.06],\n",
    "                'class_weight': ('balanced', None),\n",
    "                'max_iter': [10000]\n",
    "               }\n",
    "\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_linsvc = GridSearchCV(LinearSVC(), param_grid=param_linsvc, cv=5, scoring='precision',#'recall',#mcc_scorer, \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_linsvc.fit(X_train_clicked, y_train_clicked)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_linsvc.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_linsvc.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clicked = grid_linsvc.best_estimator_.predict(X_test_clicked)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test_clicked, y_pred_clicked), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test_clicked, y_pred_clicked)))\n",
    " \n",
    "# show the classification report\n",
    "print(classification_report(y_test_clicked, y_pred_clicked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_smote = dfr.copy()\n",
    "\n",
    "# split data into feature and target \n",
    "X_smote = dfr_smote['text'].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "# X = np.array(dfr['text'].apply(lambda x: len(x))).reshape(-1, 1)\n",
    "\n",
    "# dfr.eval('useful_cool = useful + cool', inplace=True)\n",
    "# y = dfr['useful_cool'].apply(lambda x: 1 if x > 1 else 0)\n",
    "# y = dfr['useful'].apply(lambda x: 1 if x > 1 else 0)\n",
    "y_smote = dfr_smote['useful'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# split data into train and test set\n",
    "X_train_smote, X_test, y_train_smote, y_test = train_test_split(X_smote, y_smote, random_state=RSEED, stratify=y_smote)\n",
    "# fit and apply the vectorizer\n",
    "X_train_smote = vectorizer.fit_transform(X_train_smote)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_linsvc = {'penalty':('l1','l2'),\n",
    "                'loss': ('hinge', 'squared_hinge'),\n",
    "                # 'C': [0.5, 1, 3, 5, 10],\n",
    "                'C': [0.5, 1],\n",
    "                'class_weight': ('balanced', None),\n",
    "                'max_iter': [1000]\n",
    "               }\n",
    "\n",
    "# mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_linsvc = GridSearchCV(LinearSVC(), param_grid=param_linsvc, cv=5, scoring='f1',#'precision',#'recall',#mcc_scorer, \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_linsvc.fit(X_train_smote, y_train_smote)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_linsvc.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_linsvc.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train\")\n",
    "y_pred_train = grid_linsvc.best_estimator_.predict(X_train_smote)\n",
    "print(classification_report(y_train_smote, y_pred_train))\n",
    " \n",
    "\n",
    "y_pred_smote = grid_linsvc.best_estimator_.predict(X_test)\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_smote), annot=True, fmt='g')\n",
    "# print(mcc(confusion_matrix(y_test, y_pred_smote)))\n",
    "print(\"test\")\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred_smote))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b1df77f38ddc0e9cd99154923c4962065f4473621571c66cacae5d8388dd82d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
