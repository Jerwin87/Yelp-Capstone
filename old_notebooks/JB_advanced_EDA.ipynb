{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take a look on all three, now on the merged dataset and looking for research-question specific correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing basic eda tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib as mp\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#time and warnings\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "#settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "sns.set_context('poster', font_scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in final_clean.csv (see JB_giga_merge)\n",
    "complete = pd.read_csv('final_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of reviews: ', len(complete))\n",
    "print('Positive reviews: ', len(complete[complete['stars_x'] >= 4]))\n",
    "print('Neutral reviews: ', len(complete[complete['stars_x'] == 3]))\n",
    "print('Negative reviews: ', len(complete[complete['stars_x'] <= 2]))\n",
    "print('Useful reviews: ', len(complete[complete['useful_x'] > 0]))\n",
    "print('Cool reviews: ', len(complete[complete['cool_x'] > 0]))\n",
    "print('Funny reviews: ', len(complete[complete['funny_x'] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframes, based on converted .json-files - see 'jw_importing_full_review.ipynb' \n",
    "\n",
    "review =    pd.read_csv('/Volumes/Samsung_T5/Data_Science_BootCamp/capstone/Yelp-Capstone/data/review_1819.csv')\n",
    "#business =  pd.read_csv('/Volumes/Samsung_T5/Data_Science_BootCamp/capstone/Yelp-Capstone/data/business.csv')\n",
    "#users =     pd.read_csv('/Volumes/Samsung_T5/Data_Science_BootCamp/capstone/Yelp-Capstone/data/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe that contains top 30 rated business sorted by the number of positive reviews\n",
    "biz_good_rating = business[(business['stars'] >= 4) & (business['review_count'] > 300)]\n",
    "top_rated = biz_good_rating[['name', \n",
    "                             'review_count', \n",
    "                             'stars',\n",
    "                            'categories']].sort_values(by='review_count', ascending=False)[:30]\n",
    "\n",
    "#plotting the top 30 businesses\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(data = top_rated, x = 'review_count', y = 'name')\n",
    "plt.ylabel('Business Name', fontsize=12)\n",
    "plt.xlabel('Number of Positive Reviews', fontsize=12)\n",
    "plt.title('Top Rated Businesses', fontsize=15)\n",
    "plt.show();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which Categories are getting top reviews?\n",
    "\n",
    "#separating values in categories and saving it to a list, and removing leading and trailing white space\n",
    "cat_top_rated_list = top_rated.categories.str.split(';').sum()\n",
    "cat_top_rated_list = [x.strip() for x in cat_top_rated_list]\n",
    "\n",
    "#converting given values to a dictionary\n",
    "cat_top_rated_dict = {}\n",
    "for c in range(len(cat_top_rated_list)):\n",
    "    cat_top_rated_dict[cat_top_rated_list[c]] = cat_top_rated_list.count(cat_top_rated_list[c])\n",
    "\n",
    "#converting the given dictionary to a DataFrame with categories of top reviewed businesses\n",
    "cat_top_rated = pd.DataFrame.from_dict(data = cat_top_rated_dict,orient=\"index\")\n",
    "cat_top_rated.reset_index(inplace = True)\n",
    "cat_top_rated.columns = ['category', 'occurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the share of each category present in the top 30 reviewed businesses\n",
    "size = cat_top_rated.nlargest(10,'occurance')['occurance']\n",
    "label = cat_top_rated.nlargest(10,'occurance')['category']\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data = cat_top_rated, x = size, y = label, palette = 'Set2')\n",
    "plt.ylabel('Business Category', fontsize=12)\n",
    "plt.xlabel('Number of Occurence', fontsize=12)\n",
    "plt.title('Categories of Top Reviewed Businesses', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing top 10 businesses with most rewiews\n",
    "most_reviewed = business[['name', \n",
    "                        'review_count']].reset_index().sort_values(by='review_count', \n",
    "                                                                            ascending=False)[:10]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data = most_reviewed, x = 'review_count', y = 'name', palette = 'Set3')\n",
    "plt.ylabel('Business Name', fontsize=12)\n",
    "plt.xlabel('Number of Reviews', fontsize=12)\n",
    "plt.title('Top 10 Businesses with most reviews', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words in bad reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe with only 1-star reviews\n",
    "bad_words_cond = complete[complete['stars_x'] == 1]\n",
    "bad_words = bad_words_cond[['name_x',\n",
    "                            'stars_x', \n",
    "                            'text', \n",
    "                            'categories']].reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the dataframe: ', bad_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#loading in the language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#initializing doc object\n",
    "doc = list(nlp.pipe(bad_words.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at WordClouds, mainly for visuals, inspired by JW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# importing all needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set Randomseed\n",
    "RSEED = 42\n",
    "\n",
    "# import needed functions\n",
    "#from modeling.preprocessing import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-complete-exploratory-data-analysis-and-visualization-for-text-data-29fb1b96fb6a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the stopword list:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# update the stopwords after generating the first few clouds with non decisive words\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "# create a wordcloud using all the text in text\n",
    "text = \" \".join(text for text in complete.text)\n",
    "\n",
    "#remove the stopwords from the text\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30f96410a7f26622e9d5c56d0a243d7625b85af6728e4db58912a9d29578a10c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
