{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, LSTM, Bidirectional, BatchNormalization, TextVectorization, Layer, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.metrics import Precision\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set Randomseed\n",
    "RSEED = 42\n",
    "\n",
    "# import needed functions\n",
    "from scripts.processing import *\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "vocab_size = 100000\n",
    "\n",
    "# Dimension of the dense embedding.\n",
    "embedding_dim = 128\n",
    "\n",
    "# Max number of words in each review.\n",
    "max_length = 200\n",
    "\n",
    "# Truncate and padding options\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and use the first 500k (to be faster on testruns)\n",
    "\n",
    "dfr = pd.read_csv('../data/yelp_dataset/review_1819.csv')\n",
    "dfr = dfr[:400000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geo outlier businesses \n",
    "dfr.drop(dfr[(dfr.business_id == 'wKwCbAACZRAqyZkQzeBNeg')].index, inplace=True)\n",
    "dfr.drop(dfr[(dfr.business_id == 'g0fYqQRRKmYIfChE4jMLsg')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataset to text and rating\n",
    "dataset = dfr[['text', 'useful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# filter for only english reviews and remove the language line used for filtering\n",
    "dataset = language_processing(dfr)\n",
    "dataset.drop('language', axis=1, inplace=True)\n",
    "\n",
    "#apply function for textcleaning and make sure everything looks as planned\n",
    "dataset[\"text\"] = dataset[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284030, 1) (284030,)\n",
      "(71008, 1) (71008,)\n"
     ]
    }
   ],
   "source": [
    "# define feature and target\n",
    "review = dataset[['text']]\n",
    "target = dataset[\"useful\"].apply(lambda x: 1 if x > 0 else 0).values\n",
    "\n",
    "# split the dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(review, target, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132409 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#apply tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train['text'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train tensor: (284030, 200)\n",
      "Shape of validation tensor: (71008, 200)\n"
     ]
    }
   ],
   "source": [
    "# transform feature to tensors and pad for better comparison\n",
    "train_seq = tokenizer.texts_to_sequences(X_train['text'])\n",
    "train_padded = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_seq = tokenizer.texts_to_sequences(X_test['text'])\n",
    "test_padded = pad_sequences(test_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print('Shape of train tensor:', train_padded.shape)\n",
    "print('Shape of validation tensor:', test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate labels for target\n",
    "training_labels = y_train\n",
    "test_labels = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a train set with the tokenized text and all the other features\n",
    "X_train.drop(['text'], axis=1, inplace=True)\n",
    "train_token = pd.DataFrame(train_padded)\n",
    "train_con = X_train.reset_index().join(train_token)\n",
    "train_con.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "# do the same steps for the test set\n",
    "X_test.drop(['text'], axis=1, inplace=True)\n",
    "test_token = pd.DataFrame(test_padded)\n",
    "test_con = X_test.reset_index().join(test_token)\n",
    "test_con.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    " standardize='lower_and_strip_punctuation', \n",
    " ngrams=3,\n",
    " max_tokens=vocab_size,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_length)\n",
    "\n",
    "vectorize_layer.adapt(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate and define the model\n",
    "text_in = Input(shape=(1,), dtype=tf.string)\n",
    "vector = vectorize_layer(text_in)\n",
    "embedding = Embedding(vocab_size, embedding_dim)(vector)\n",
    "text_bidir_lstm_1 = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n",
    "text_dropout_1 = Dropout(0.5)(text_bidir_lstm_1)\n",
    "text_bidir_lstm_2 = Bidirectional(LSTM(128, return_sequences=True))(text_dropout_1)\n",
    "text_dropout_2 = Dropout(0.5)(text_bidir_lstm_2)\n",
    "text_attention = attention()(text_dropout_2)\n",
    "text_dense = Dense(64, activation='relu')(text_attention)\n",
    "text_batch_norm_1 = BatchNormalization()(text_dense)\n",
    "text_out = Dropout(0.5)(text_batch_norm_1)\n",
    "\n",
    "#concat = concatenate([text_out, num_in])\n",
    "dense_1 = Dense(128, activation='relu')(text_out)\n",
    "batch_norm_1 = BatchNormalization()(dense_1)\n",
    "dropout_1 = Dropout(0.5)(batch_norm_1)\n",
    "dense_2 = Dense(32, activation='relu')(dropout_1)\n",
    "batch_norm_2 = BatchNormalization()(dense_2)\n",
    "dropout_2 = Dropout(0.5)(batch_norm_2)\n",
    "\n",
    "out = Dense(1, activation='sigmoid')(dropout_2)\n",
    "model = Model(inputs=[text_in], outputs=[out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='binary_focal_crossentropy', optimizer='adam', metrics=['Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history in tensorboard\n",
    "log_dir = \"../logs/new/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_path = \"../training/model_5/cp.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 15:27:11.911845: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:27:12.783860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:27:13.281198: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:27:15.842398: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:27:15.865933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888/888 [==============================] - ETA: 0s - loss: 0.1293 - precision: 0.7511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 15:32:45.842450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:32:46.119607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-05 15:32:46.135853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ../training/model_5/cp.ckpt\n",
      "888/888 [==============================] - 362s 399ms/step - loss: 0.1293 - precision: 0.7511 - val_loss: 0.1727 - val_precision: 0.5694\n",
      "Epoch 2/4\n",
      "888/888 [==============================] - ETA: 0s - loss: 0.1203 - precision: 0.7796\n",
      "Epoch 2: saving model to ../training/model_5/cp.ckpt\n",
      "888/888 [==============================] - 370s 417ms/step - loss: 0.1203 - precision: 0.7796 - val_loss: 0.1785 - val_precision: 0.5585\n",
      "Epoch 3/4\n",
      "888/888 [==============================] - ETA: 0s - loss: 0.1102 - precision: 0.8096\n",
      "Epoch 3: saving model to ../training/model_5/cp.ckpt\n",
      "888/888 [==============================] - 466s 525ms/step - loss: 0.1102 - precision: 0.8096 - val_loss: 0.2035 - val_precision: 0.5461\n",
      "Epoch 4/4\n",
      "888/888 [==============================] - ETA: 0s - loss: 0.1018 - precision: 0.8315\n",
      "Epoch 4: saving model to ../training/model_5/cp.ckpt\n",
      "888/888 [==============================] - 506s 570ms/step - loss: 0.1018 - precision: 0.8315 - val_loss: 0.2310 - val_precision: 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/model_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../saved_model/model_5/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x29a5a9490> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x29a5b2070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# set parameters and train the model\n",
    "epochs = 4\n",
    "batch_size = 256\n",
    "\n",
    "history = model.fit(train_con, training_labels, shuffle=True ,\n",
    "                    epochs=epochs, batch_size=batch_size, \n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[tensorboard_callback, cp_callback])\n",
    "\n",
    "model.save('../saved_model/model_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "278/278 [==============================] - 43s 154ms/step - loss: 0.2285 - precision: 0.5384\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_con, test_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_labels = (model.predict(test_con) > 0.5).astype('int32')\n",
    "sns.heatmap(tf.math.confusion_matrix(test_labels, pred_labels), annot=True, fmt='g', cmap='viridis_r', vmin=0, vmax=40000, linewidth=0.01, linecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.71      0.67     42940\n",
      "           1       0.47      0.39      0.43     28068\n",
      "\n",
      "    accuracy                           0.58     71008\n",
      "   macro avg       0.55      0.55      0.55     71008\n",
      "weighted avg       0.57      0.58      0.58     71008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show the classification report\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seq = tokenizer.texts_to_sequences(review)\n",
    "text_padded = pad_sequences(text_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (355038)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/felixbecker/neuefische/Yelp-Capstone/notebooks/jw_tf_compare_new_features.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/felixbecker/neuefische/Yelp-Capstone/notebooks/jw_tf_compare_new_features.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset[\u001b[39m'\u001b[39;49m\u001b[39mhelpfulness\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(text_padded)\n",
      "File \u001b[0;32m~/neuefische/Yelp-Capstone/.venv/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/neuefische/Yelp-Capstone/.venv/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/neuefische/Yelp-Capstone/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4532\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4534\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4535\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4536\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/neuefische/Yelp-Capstone/.venv/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1) does not match length of index (355038)"
     ]
    }
   ],
   "source": [
    "dataset['helpfulness'] = model.predict(text_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort_values('helpfulness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[1414387].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr['helpfulness'] = dataset['helpfulness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_ea = dfr.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_ea.loc[170477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_ea.query('business_id == \"toRNyzwkG59NYJP2ti-qTQ\"').sort_values('helpfulness')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a25c5467bd72a15a44db8f6702eef707e4b4c2171cfa5fa542b91e92dc8d903c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
