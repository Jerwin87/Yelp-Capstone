{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from gensim import corpora, models\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import numpy as np\n",
    "from gensim.models import Phrases\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "from scripts.processing import *\n",
    "from scripts.mk_categories_word2vec_addmaincat import *\n",
    "\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV\n",
    "df = pd.read_csv('../data/yelp_dataset/review_1819.csv')\n",
    "# maincat = select_dataset_by_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_maincat = df.reset_index().merge(maincat.reset_index(), on='business_id', how='left') # add suffixes…\n",
    "# maincat_restr = [\"beauty & spas\", \"fitness & instruction\"]\n",
    "# df_maincat = df_maincat.query('maincat == @maincat_restr')\n",
    "# restricting the dataset to a subset of maincats does not seem to change much…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_maincat.groupby('maincat').count().review_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_maincat = language_processing(df_maincat, verbose=True) \n",
    "df = language_processing(df, verbose=True) # why such results with some maincats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py\n",
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "documents = []\n",
    "# for document in df_maincat.iloc[0:50000].text:\n",
    "# for document in df_maincat.iloc[0:100000].text:\n",
    "for document in df.iloc[0:100000].text:\n",
    "# for document in df.iloc[0:1000000].text:\n",
    "    documents.append(document)\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "\n",
    "# TODO use different tokenizer and lemmatizer? (also elsewhere in this notebook)\n",
    "# texts = [ [lemmatizer.lemmatize(token) for token in [ token for token in word_tokenize(document.translate(str.maketrans('', '', string.punctuation)).lower()) ] if token not in stoplist] for document in documents ]\n",
    "texts = [ [ token for token in word_tokenize(document.lower()) if token not in stoplist] for document in documents ] # instead of stoplist use only no_above/below as below??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "texts = [[token for token in doc if not token.isnumeric()] for doc in texts]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "texts = [[token for token in doc if len(token) > 1] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "texts = [ [lemmatizer.lemmatize(token) for token in doc] for doc in texts ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (slightly adapted) from https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20[now 10] times or more).\n",
    "bigram = Phrases(texts, min_count=10) # TODO check if something can be improved (not really improving anything like this…)\n",
    "for idx in range(len(texts)):\n",
    "    for token in bigram[texts[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            texts[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = defaultdict(int)\n",
    "# for text in texts:\n",
    "#     for token in text:\n",
    "#         freq[token] += 1\n",
    "# \n",
    "# texts = [\n",
    "#     [token for token in text if freq[token] > 1]\n",
    "#     for text in texts\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model = models.LdaMulticore(corpus_tfidf, id2word=dictionary, num_topics=NUM_TOPICS)\n",
    "# lda_model = models.LdaMulticore(corpus_tfidf, id2word=dictionary, num_topics=NUM_TOPICS, passes=20, iterations=400, eval_every=1)\n",
    "# lda_model = models.LdaMulticore(corpus_tfidf, id2word=dictionary, num_topics=NUM_TOPICS, passes=10, iterations=200, eval_every=1)\n",
    "# lda_model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=NUM_TOPICS, alpha='auto', eta='auto', passes=20, iterations=400) # cf. also https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\n",
    "# corpus_lda = lda_model[corpus]\n",
    "\n",
    "lda_model = models.LdaMulticore(corpus, id2word=dictionary, num_topics=NUM_TOPICS, passes=10, iterations=200, eval_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_topics = df.iloc[1100000:1200000].copy() # copy necessary?\n",
    "df_topics = df.iloc[200000:300000].copy() # copy necessary?\n",
    "# df_topics = df.iloc[1000000:].copy() # copy necessary?\n",
    "# df_topics = df_maincat.iloc[200000:300000].copy() # copy necessary?\n",
    "# df_topics = df_maincat.iloc[50000:100000].copy() # copy necessary?\n",
    "for i in range(NUM_TOPICS):\n",
    "    df_topics[f\"topic_{i}\"] = 0\n",
    "    # df_topics[f\"topic_{i}\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_topics.iterrows():\n",
    "    unseen_doc_text = row.text\n",
    "    unseen_doc_text_tok = [lemmatizer.lemmatize(token) for token in [ token for token in word_tokenize(unseen_doc_text.translate(str.maketrans('', '', string.punctuation)).lower()) ] if token not in stoplist]\n",
    "    # unseen_doc_text_tok = [token for token in unseen_doc_text.translate(str.maketrans('', '', string.punctuation)).lower().split() if token not in stoplist]\n",
    "    unseen_doc = dictionary.doc2bow(unseen_doc_text_tok)\n",
    "    vector = lda_model[unseen_doc]\n",
    "    # print(vector)\n",
    "    for topic in vector:\n",
    "        df_topics.loc[idx, f\"topic_{topic[0]}\"] = 1 if topic[1] > 0 else 0 # different threshold?\n",
    "        # df_topics.loc[idx, f\"topic_{topic[0]}\"] = topic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into feature and target \n",
    "# maincat_dummies = pd.get_dummies(df_topics.maincat, drop_first=True)\n",
    "# X = pd.concat([maincat_dummies, df_topics.filter(like='topic')], axis=1)\n",
    "# worse with main cat dummies…\n",
    "\n",
    "X = df_topics.filter(like='topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_topics['useful'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RSEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(cm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    return (tp*tn-fp*fn) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = logreg.coef_[0]\n",
    "\n",
    "for item in np.argsort(coef)[-1:-6:-1]:\n",
    "    print(coef[item], lda_model.print_topic(item))\n",
    "print(\"=\"*40)\n",
    "for item in np.argsort(coef)[:5]:\n",
    "    print(coef[item], lda_model.print_topic(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_logreg = {'penalty':('l1','l2', 'elasticnet'),#, None),\n",
    "                'C': [9, 9.5, 10, 10.5, 11],\n",
    "                'solver': ['liblinear', 'lbfgs', 'sag'],#, 'newton-cg', 'saga']\n",
    "               }\n",
    "\n",
    "# mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_logreg = GridSearchCV(LogisticRegression(), param_grid=param_logreg, cv=5, scoring='precision',#mcc_scorer, \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_logreg.fit(X_train, y_train)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_logreg.best_estimator_.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    " \n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "# fit the model\n",
    "LSVC.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = LSVC.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSVC.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aram_linsvc = {'penalty':('l1','l2'),\n",
    "                'loss': ('hinge', 'squared_hinge'),\n",
    "                'C': [0.05, 0.06, 0.065],\n",
    "                'class_weight': ('balanced', None),\n",
    "                'max_iter': [10000]\n",
    "               }\n",
    "\n",
    "# mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_linsvc = GridSearchCV(LinearSVC(), param_grid=param_linsvc, cv=5, scoring='precision',#'recall',#mcc_scorer, \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_linsvc.fit(X_train, y_train)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_linsvc.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_linsvc.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_linsvc.best_estimator_.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    " \n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "xtree = ExtraTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "xtree.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = xtree.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying the separate script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    " \n",
    "from scripts.topic_feature import *\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    " \n",
    "import seaborn as sns\n",
    " \n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 40\n",
    "df = pd.read_csv('../data/yelp_dataset/review_1819.csv')\n",
    "lda_model, dictionary = train_LDA_model(df, end=100000, num_topics=NUM_TOPICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = add_topics(df, lda_model, dictionary, begin=200000, end=300000, num_topics=NUM_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df.merge(X, on='review_id', how='left').fillna(0)\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.iloc[199990:200010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[200000:300000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[200000:300000]['useful'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RSEED, stratify=y)\n",
    "\n",
    "# def mcc(cm):\n",
    "#     tn, fp = cm[0]\n",
    "#     fn, tp = cm[1]\n",
    "#     return (tp*tn-fp*fn) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5\n",
    "\n",
    "# initialize the Classifier\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_topics = pd.read_csv('../scripts/review_1819_topics_full.csv')\n",
    "review_topics = pd.read_csv('../scripts/review_1819_topics_train500000_annotfull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = review_topics.filter(like='topic', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = review_topics['useful'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RSEED, stratify=y)\n",
    "\n",
    "def mcc(cm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    return (tp*tn-fp*fn) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5\n",
    "\n",
    "# initialize the Classifier\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "2b1df77f38ddc0e9cd99154923c4962065f4473621571c66cacae5d8388dd82d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
