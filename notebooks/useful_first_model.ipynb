{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# importing all needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer, matthews_corrcoef\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import re\n",
    "import unicodedata\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set Randomseed\n",
    "RSEED = 42\n",
    "\n",
    "# import needed functions\n",
    "from scripts.processing import *\n",
    "# from scripts.mk_categories_word2vec_addmaincat import select_dataset_by_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = pd.read_csv('../data/yelp_dataset/review_1819.csv').iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = language_processing(dfr, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr.query('useful > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "additional_stopwords = ['one', 'go', 'also', 'would', 'get', 'got']\n",
    "stopwords.extend(additional_stopwords)\n",
    "\n",
    "def text_cleaning(txt):\n",
    "    # txt = (unicodedata.normalize('NFKD', txt)).encode('ascii', 'ignore').decode('utf-8', 'ignore').lower()\n",
    "    txt = txt.lower()\n",
    "    words = re.sub(r'[^\\w\\s]', '', txt).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maincat = select_dataset_by_cat(categories=None, save_to_csv=False)\n",
    "# dfr_maincat = dfr.set_index('business_id').join(maincat.set_index('business_id'), on='business_id', how='left', rsuffix='_business')\n",
    "# dfr = dfr_maincat.query('maincat == \"restaurants\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize vectorizer Parameter nach Susan Li\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, \n",
    "                             min_df=5, \n",
    "                             norm='l2', \n",
    "                             encoding='utf-8', \n",
    "                             ngram_range=(1, 5), \n",
    "                             stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into feature and target \n",
    "X = dfr['text'].apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "# X = np.array(dfr['text'].apply(lambda x: len(x))).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfr.eval('useful_cool = useful + cool', inplace=True)\n",
    "# y = dfr['useful_cool'].apply(lambda x: 1 if x > 1 else 0)\n",
    "# y = dfr['useful'].apply(lambda x: 1 if x > 1 else 0)\n",
    "y = dfr['useful'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RSEED, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the vectorizer\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(cm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    return (tp*tn-fp*fn) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_logreg = {'penalty':('l1','l2', 'elasticnet'),#, None),\n",
    "                'C': [5, 8, 9, 10, 20, 30],\n",
    "                'solver': ['liblinear', 'lbfgs', 'sag'],#, 'newton-cg', 'saga']\n",
    "               }\n",
    "\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_logreg = GridSearchCV(LogisticRegression(), param_grid=param_logreg, cv=5, scoring='precision',#mcc_scorer, \n",
    "                           verbose=0, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_logreg.fit(X_train, y_train)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_logreg.best_estimator_.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "tree.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "xtree = ExtraTreeClassifier()\n",
    "\n",
    "# fit the model\n",
    "xtree.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = xtree.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "# fit the model\n",
    "MNB.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = MNB.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "# fit the model\n",
    "BNB.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = BNB.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "# fit the model\n",
    "LSVC.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = LSVC.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_linsvc = {'penalty':('l1','l2'),\n",
    "                'loss': ('hinge', 'squared_hinge'),\n",
    "                'C': [0.05, 0.06, 0.065, 0.07, 0.075, 0.08],\n",
    "                'class_weight': ('balanced', None),\n",
    "                'max_iter': [10000]\n",
    "               }\n",
    "\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "grid_linsvc = GridSearchCV(LinearSVC(), param_grid=param_linsvc, cv=5, scoring='precision',#'recall',#mcc_scorer, \n",
    "                           verbose=5, n_jobs=-1)\n",
    "\n",
    "# fit the model\n",
    "grid_linsvc.fit(X_train, y_train)    \n",
    "\n",
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_linsvc.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_linsvc.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_linsvc.best_estimator_.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "print(mcc(confusion_matrix(y_test, y_pred)))\n",
    " \n",
    "# show the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the Classifier\n",
    "# knn = KNeighborsClassifier()\n",
    "# \n",
    "# # fit the model\n",
    "# knn.fit(X_train, y_train)\n",
    "# \n",
    "# # make predictions\n",
    "# y_pred = knn.predict(X_test)\n",
    "# \n",
    "# # test the model\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "# print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "# \n",
    "# # show the classification report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the Classifier\n",
    "# svc = SVC()\n",
    "# \n",
    "# # fit the model\n",
    "# svc.fit(X_train, y_train)\n",
    "# \n",
    "# # make predictions\n",
    "# y_pred = svc.predict(X_test)\n",
    "# \n",
    "# # test the model\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
    "# print(mcc(confusion_matrix(y_test, y_pred)))\n",
    "# \n",
    "# # show the classification report\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_reviews(df):\n",
    "    review_list = []\n",
    "    for idx, review in df.iterrows():\n",
    "        review_vectors = vectorizer.transform([review.text])\n",
    "        conf_score = grid_linsvc.best_estimator_.decision_function(review_vectors)\n",
    "        review_list.append((conf_score, review.text))\n",
    "\n",
    "    review_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    return review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_business_0 = dfr[dfr.business_id == dfr.business_id.unique()[0]]\n",
    "\n",
    "for i, item in enumerate(sort_reviews(dfr_business_0)):\n",
    "    # print(item)\n",
    "    print(f\"{i+1}:\\n{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_texts.json contains list of strings (each string is one review)\n",
    "with open('../data/test_texts.json') as json_f:\n",
    "    test_texts = json.load(json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'text': test_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(sort_reviews(df_test)):\n",
    "    # print(item)\n",
    "    print(f\"{i+1}:\\n{item[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b1df77f38ddc0e9cd99154923c4962065f4473621571c66cacae5d8388dd82d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
