{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# importing all needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set Randomseed\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the first 100k lines of the review file into a dataframe\n",
    "\n",
    "dfr = pd.read_csv('../data/yelp_dataset/review_1819_eng.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the stopword list:\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for textcleaning\n",
    "punctuation = ['\"', '(', ')', '-', '$', ',', '+', \"'\", \"\\n\", \"\\r\"]\n",
    "\n",
    "def clean_text(text):   \n",
    "    cleaned_text = \"\".join(u for u in text if u not in punctuation)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from the text in the initial df\n",
    "dfr['text'] = dfr['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize vectorizer Parameter nach Susan Li\n",
    "vectorizer = TfidfVectorizer(   sublinear_tf=True, \n",
    "                                min_df=5, \n",
    "                                norm='l2', \n",
    "                                encoding='latin-1', \n",
    "                                ngram_range=(1, 2), \n",
    "                                stop_words=stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into feature and target \n",
    "X = dfr['text']\n",
    "y = dfr['stars']\n",
    "\n",
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RSEED)\n",
    "\n",
    "# fit and apply the vectorizer\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize the Classifier\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "# fit the model\n",
    "MNB.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = MNB.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, fmt='g')\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "# fit the model\n",
    "LSVC.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = LSVC.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, fmt='g')\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Classifier\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model\n",
    "logreg.fit(X_train, y_train)    \n",
    "\n",
    "# make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# test the model\n",
    "sns.heatmap(confusion_matrix(y_pred, y_test), annot=True, fmt='g')\n",
    "\n",
    "# show the classification report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ce5e151fb00091df5b1b9e0901c9540dd87c25621af86a4204e4865fde1e8b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
